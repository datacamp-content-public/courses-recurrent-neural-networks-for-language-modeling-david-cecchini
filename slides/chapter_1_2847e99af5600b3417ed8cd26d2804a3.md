---
title: Insert title here
key: 2847e99af5600b3417ed8cd26d2804a3

---
## Introduction to RNN inside keras

```yaml
type: "TitleSlide"
key: "a7bfabbdb4"
```

`@lower_third`

name: David Cecchini
title: Data Scientist, LegalBot & Demographics Pro


`@script`
In this lesson we are going to the practical implementation of the RNN models using keras.
Previously in this chapter we learned the architecture of the RNN cells, and now we will use keras to create and train RNN models.


---
## What is keras?

```yaml
type: "TwoRows"
key: "a6fc7ee15f"
```

`@part1`
Keras is a high-level API that can use Tensorflow, CNTK and Theano as background deep learning frameworks. 

Thus, in order to use keras, one of those frameworks should be installed (Tensorflow is used by default).


`@part2`
Easy to install and use: 

```
pip install keras
```

```
from keras.models import Sequential
from keras.layers import LSTM, Dense
```


`@script`
Keras is a high-level API with deep learning frameworks as background. It is possible to configure keras with Tensorflow (the default option), CNTK and Theano. The chosen framework should be installed beforehand.
To install keras, we can simply use the Python package manager pip.
After installation, we can use the pre-defined modules of keras to execute fast experimentation and research.


---
## Main keras modules

```yaml
type: "FullSlide"
key: "9fafe9f8fe"
```

`@part1`
**keras.models** contains the classes used to create and manage models: 
1. **Sequential** creates models where the next layer has the previous layer as input and the next layer as output
2. **Model** creates a generic model that can have multiple inputs and outputs (branches)

**keras.layers** contains the pre-defined layers available in keras:
1. **LSTM**, **GRU**, **Dense**, **Dropout**, **Embedding**, **Bidirectional**


`@script`
Now we will describe the main modules of keras that will be useful for the language models.
keras.models contains two classes of models: Sequential and Model. The Sequential class has a structure where each layer is applied to the model in sequence, meaning that the output of one layer is the input of the next one.
The other class is a generic definition of model that is more flexible and allows multiple inputs and outputs.
keras.layers contains the different types of layers including the LSTM and GRU cells introduced before. Other layers that we will use are Dense, Dropout and Embedding.


---
## Main keras modules (cont.)

```yaml
type: "FullSlide"
key: "c08cf53de7"
```

`@part1`
**keras.preprocessing** has many functions for pre-processing the data

1. **sequence** contains the functions for pre-processing sequence data such as **pad_sequences**

**keras.datasets** contains many data science datasets ready to be loaded and used

1. **imdb** contains the famous movie reviews dataset for sentiment classification (binary)
2. **reuters** is another dataset for multi-class classification (46 topics of news articles)


`@script`
keras.preprocessing contains useful functions for pre-processing the data. One of them is the sequence.pad_sequence method that transforms the texts into a fixed-length vectors.
Finally, the keras.datasets module contains datasets ready to be used for experimentation. We will use the IMDB dataset for sentiment classification and the Reuters news articles dataset for multi-class classification.


---
## Creating a model

```yaml
type: "FullSlide"
key: "d29b88e6ee"
```

`@part1`
It is easy to build a model in keras. Remarks:

1. The first layer (input layer) should specify the shape of the inputs
2. There are many activation functions to be used on each layer (or none, meaning that the layer will use identity function as activation)

A simple model with two dense layers:

```
from keras.models import Sequential
from keras.layers import Dense

model = Sequential()
model.add(Dense(64, activation='relu', input_dim=100))
model.add(Dense(1, activation='sigmoid'))
model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

```


`@script`
It is easy to build a model in keras, and there are just a few remarks to pay attention.
One remark is that the first layer (input layer) should specify the shape of the inputs, since the model is expecting a specific format of the data. The next layers can calculate their input shape based on the expected output shape of the previous layer.
Another remark is that there are many activation functions that can be used on each layer. A general rule is to use ReLU in the initial layers because it is fast to compute and softmax or sigmoid on the output layer. Another activation function is the hyperbolic tangent that is used for example in the LSTM cell.


---
## Training the model

```yaml
type: "FullSlide"
key: "ca29abab37"
```

`@part1`
The method **fit** trains the model on the training set

```
model.fit(X_train, y_train, epochs=10, batch_size=32)
```

1. **epochs** determine how many weight updates will be done on the model
2. **batch_size** corresponds to the size of the data that will be used on each step to avoid memory errors (when the dataset cannot fit in the memory this is crucial)


`@script`
To train the model, we use the fit method. The parameters of the method include:
1. **epochs** which is the number of weight updates that will be done on the model. Defaults to one.
2. **batch_size** that corresponds to the size of the data that will be used on each step to avoid memory errors (when the dataset cannot fit in the memory this is crucial). Defaults to 32.


---
## Model evaluation and usage

```yaml
type: "FullSlide"
key: "f7bd2ea11c"
```

`@part1`
In order to analyze the model's performance, we can use the method **evaluate**.

```
mode.evaluate(X_test, y_test, batch_size=64)
```

The method **predict** is used on new data to obtain the outputs of the model.

```
model.predict(new_data, batch_size=64)
```


`@script`
In order to analyze the model's performance, we can use the method **evaluate**. This method returns the loss and accuracy values obtained on the test dataset.
The method **predict** is used on new data to obtain the outputs of the model.


---
## Full example: IMDB Sentiment Classification

```yaml
type: "FullCodeSlide"
key: "7220f319a5"
```

`@part1`
The IMDB dataset is already loaded and the X sequences padded with size = 80

```
from keras.models import Sequential
from keras.layers import Dense, Embedding, LSTM

# Build the model
model = Sequential()
model.add(Embedding(10000, 128))
model.add(LSTM(128, dropout=0.2))
model.add(Dense(1, activation='sigmoid'))

# Compile with binary_crossentropy for binary classification
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Training
model.fit(x_train, y_train, epochs=5)

# Evaluation
score, acc = model.evaluate(x_test, y_test)

print('Test score: {0}\nTest accuracy: {1}'.format(score, acc))

```


`@script`
This slide shows the code to create, train and evaluate a simple RNN model on the IMDB dataset that is pre-loaded on the environment. 
To train the RNN model with 5 epochs on a core i7-8550U processor with 12GB of RAM memory took around 6 minutes and it achieved ~82% accuracy on the test data which is a good start.


---
## Time to practice!

```yaml
type: "FinalSlide"
key: "b9e39fe9e5"
```

`@script`
Time to practice!

